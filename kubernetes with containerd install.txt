# kubernetes with containerd and calico networking install (1 controller and 2 worker nodes)

# Setup 
#   1. 3 VMs Ubuntu 22.04, 1 control plane, 2 nodes.
#   2. Static IPs on individual VMs ctrl - 192.168.57.210, worker1 - 192.168.57.201, worker2 - 192.168.57.202
#   3. /etc/hosts hosts file includes name to IP mappings for VMs
#   4. Swap is disabled
#   5. Take snapshots prior to installation, this way you can install 
#      and revert to snapshot if needed 

#x - Project "x"

vi /etc/hosts

# add the following lines, edit project "x"
192.168.57.210  project_x-k8s-ctrl01
192.168.57.201  project_x-k8s-worket01
192.168.57.202  project_x-k8s-worker02

# add the following lines, no project yet :)
192.168.57.210  k8s-ctrl01
192.168.57.201  k8s-worket01
192.168.57.202  k8s-worker02

# ctrl1 - Controller node:
ssh k8s-adm@k8s-ctrl01
# worker1
ssh k8s-adm@k8s-worker1
# worker2
ssh k8s-adm@k8s-worker02

# On all nodes Control PLane & Worker nodes

# - Disable swap, swapoff then edit your fstab removing any entry for swap partitions
# You can recover the space with fdisk. You may want to reboot to ensure your config is ok. 
sudo swapoff -a
sudo vi /etc/fstab
# comment
# /swap.img	none	swap	sw	0	0
 
# containerd prerequisites, and load two modules and configure them to load on boot
# https://kubernetes.io/docs/setup/production-environment/container-runtimes/
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system

# - Install containerd

sudo apt-get install -y containerd
# Create a containerd configuration file
sudo mkdir -p /etc/containerd 
sudo containerd config default | sudo tee /etc/containerd/config.toml

# Set the cgroup driver for containerd to systemd which is required for the kubelet.
# For more information on this config file see:
# https://github.com/containerd/cri/blob/master/docs/config.md and also
# https://github.com/containerd/containerd/blob/master/docs/ops.md

# At the end of this section, change SystemdCgroup = false to SystemdCgroup = true
#        [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
#        ...
#          [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
            SystemdCgroup = true
# You can use sed to swap in true
sudo sed -i 's/            SystemdCgroup = false/            SystemdCgroup = true/' /etc/containerd/config.toml

# Verify the change was made
sudo vi /etc/containerd/config.toml

# Restart containerd with the new configuration
sudo systemctl restart containerd

# Install kubernetes

sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# Update the package list & check the latest version available
sudo apt-get update
apt-cache policy kubelet | head -n 20 

# For the latest version
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl

# Install the required packages, if needed we can request a specific version. 
# Pick the same version you used on the Control Plane Node in 0-PackageInstallation-containerd.sh
# VERSION=1.28.10-00
# sudo apt-get install -y kubelet=$VERSION kubeadm=$VERSION kubectl=$VERSION

# Mark hold, disable automatic updates for containerd kubelet kubeadm kubectl services
sudo apt-mark hold containerd kubelet kubeadm kubectl
# Verify the mark hold was made
apt-mark showhold

#Check the status of our kubelet and our container runtime.
#The kubelet will enter a crashloop until it's joined
sudo systemctl status kubelet.service 
sudo systemctl status containerd.service 

#Ensure both are set to start when the system starts up.
sudo systemctl enable kubelet.service
sudo systemctl enable containerd.service

# Bootstraping a Cluster with kubeadm

# Certificates Authority
#    self signed Certificate Authority (CA)
#    can be part of an external PKI
#    Securing cluster communications
#     API Server
#    Authentication of users and cluster components
#  /etc/kubernetes/pki
#    Distributed to each Node

# kubeadm Create kubeconfig Files
#   Used to define how to connect to your Cluster
#    Client certificates
#    Cluster API Server metwork location
#  /etc/kubernetes
#    admin.conf (kubernetes-admin)
#    kubelet.conf
#    controller-manager.conf
#    scheduler.conf

# Static Pod Manifest
#   Manifest describes a configuration
#  /ect/kubernetes/manifests
#    etcd
#    API Server
#    Controller Manager
#    scheduler
#  Wathed by the kubelet started automatically when the system starts and over time

# Pod Networking
#   Single, un NATed IP address per Pod
#   Direct routing
#    Configure infrastructure to support IP reachability between Pods and Nodes
#   Overlay networking (SDN)
#    Flannel -Layer 3 virtual network
#    Calico - L3 and policy based traffic management
#    Weave Net - multi-host network

# !!! On the Control Plane nod only

# - Creating a Cluster
# Create our kubernetes cluster, specify a pod network range matching that in calico.yaml! 
# Only on the Control Plane Node, download the yaml files for the pod network.
wget https://raw.githubusercontent.com/projectcalico/calico/master/manifests/calico.yaml

# Look inside calico.yaml and find the setting for Pod Network IP address range CALICO_IPV4POOL_CIDR, 
# adjust if needed for your infrastructure to ensure that the Pod network IP
# range doesn't overlap with other networks in our infrastructure.
vi calico.yaml

# Creating a Control Plane Node

kubeadm config print init-defaults | tee ClusterConfiguration.yaml
vi ClusterConfiguration.yaml

# You can now just use kubeadm init to bootstrap the cluster
sudo kubeadm init \
  --config=ClusterConfiguration.yaml \
  --cri-socket /run/containerd/containerd.sock

# !!! You can now just use kubeadm init to bootstrap the cluster and specify different version
# sudo kubeadm init --kubernetes-version v1.26.0

#Configure our account on the Control Plane Node to have admin access to the API server from a non-privileged account.
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config


# - Creating a Pod Network
#Deploy yaml file for your pod network.
kubectl apply -f calico.yaml

# Look for the all the system pods and calico pods to change to Running. 
# The DNS pod won't start (pending) until the Pod network is deployed and Running.
kubectl get pods --all-namespaces

# Gives you output over time, rather than repainting the screen on each iteration.
kubectl get pods --all-namespaces --watch

# All system pods should be Running
kubectl get pods --all-namespaces

# Get a list of our current nodes, just the Control Plane Node Node...should be Ready.
kubectl get nodes 

# !!! If token expired
#On c1-cp1 - if you didn't keep the output, on the Control Plane Node, you can get the token.
kubeadm token list

# If you need to generate a new token, perhaps the old one timed out/expired.
kubeadm token create

# On the Control Plane Node, you can find the CA cert hash.
openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //'

# You can also use print-join-command to generate token and print the join command in the proper format
# COPY THIS INTO YOUR CLIPBOARD
kubeadm token create --print-join-command


# Adding the Nodes to a Cluster

ssh k8s-adm@k8s-worker1

kubeadm join 192.168.57.210:6443 --token abcdef.0123456789abcdef \
	--discovery-token-ca-cert-hash sha256:44d8efe3aa9043939cc44a53a53f5217111cde68a89807cf014b2bbc342aaffd

ssh k8s-adm@k8s-worker1

kubeadm join 192.168.57.210:6443 --token abcdef.0123456789abcdef \
	--discovery-token-ca-cert-hash sha256:44d8efe3aa9043939cc44a53a53f5217111cde68a89807cf014b2bbc342aaffd